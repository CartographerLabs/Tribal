{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\n",
      "No model chosen, model unsloth/Llama-3.1-Storm-8B-bnb-4bit selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import from_networkx\n",
    "from sklearn.model_selection import train_test_split\n",
    "import networkx as nx\n",
    "from objects.user import UserObject\n",
    "from pprint import pprint \n",
    "from utils.feature_extractor import FeatureExtractor\n",
    "from utils.config_manager import ConfigManager\n",
    "from data_set_managers.json_dataset_manager import JsonDatasetManager\n",
    "from objects.timeline import TimelineObject\n",
    "import json \n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading telegram post data...\n",
      "Loading ground truth extremist post data...\n",
      "Initializing FeatureExtractor...\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "No model chosen, model unsloth/Llama-3.1-Storm-8B-bnb-4bit selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JS\\Documents\\tools\\Tribal\\Tribal\\utils\\feature_extractor.py:50: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  embeddings = torch.tensor(embeddings, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.005771621507711263\n",
      "Epoch 2, Loss: 6.629083414521009e-06\n",
      "Epoch 3, Loss: 1.174403536726617e-06\n",
      "Epoch 4, Loss: 2.681721007951826e-07\n",
      "Epoch 5, Loss: 6.605760283702735e-08\n"
     ]
    }
   ],
   "source": [
    "# Block 2: Load data\n",
    "print(\"Loading telegram post data...\")\n",
    "telegram_post_data = JsonDatasetManager(str(ConfigManager().location_of_post_data))\n",
    "\n",
    "print(\"Loading ground truth extremist post data...\")\n",
    "ground_truth_extremist_post_data = JsonDatasetManager(ConfigManager().location_of_ground_truth_extremist_post_data)\n",
    "\n",
    "# Initialize feature extractor\n",
    "print(\"Initializing FeatureExtractor...\")\n",
    "feature_extractor = FeatureExtractor(\n",
    "    telegram_post_data.get_list_of_posts(), \n",
    "    ground_truth_extremist_post_data.get_list_of_posts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: Prepare user data and graph structure\n",
    "users = telegram_post_data.get_all_user_data()\n",
    "\n",
    "# Build the graph based on users' connections and features\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Initialize mappings for themes, operational status, and roles\n",
    "theme_to_num = {}\n",
    "num_to_theme = {}\n",
    "\n",
    "ops_to_num = {}\n",
    "num_to_ops = {}\n",
    "\n",
    "role_to_num = {}\n",
    "num_to_role = {}\n",
    "\n",
    "node_labels = []  # Placeholder for node labels\n",
    "node_features = []  # Placeholder for feature vectors\n",
    "\n",
    "CHOSEN_OVERALL_WINDOW_START, CHOSEN_OVERALL_WINDOW_END = telegram_post_data.get_timeframe()\n",
    "posts = telegram_post_data.get_all_user_data(\n",
    "    start_time=CHOSEN_OVERALL_WINDOW_START, end_time=CHOSEN_OVERALL_WINDOW_END\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file does not exist. Creating a new window.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\quantizers\\auto.py:174: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "C:\\Users\\JS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\llama\\modeling_llama.py:660: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action, indicators of seeking knowledge or skills related to carrying out violence, discussion about logistics or coordination with others, or leakage of intentions or plans. The tone and emotional intensity of the post do not suggest an individual close to taking action. The content does not align with the research paper's findings on online signals of extremist mobilization.\" }\n",
      "{ \"theme\": \"Travel\", \"reasoning\": \"The post talks about visiting the beach, which is a common tourist destination, and enjoying sunshine, indicating a trip or vacation.\" }\n",
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action, nor does it indicate the user is seeking to acquire knowledge or skills related to carrying out violence. There is no discussion about logistics, timelines, specific targets, or coordination with others. The text does not contain any 'leakage' revealing intentions or plans. The overall tone is neutral, without excessive punctuation marks, strong expressions of anger or excitement, or a sense of urgency. Therefore, the post exhibits no signs of operational planning for extremist activities.\" }\n",
      "{\"theme\": \"Travel\", \"reasoning\": \"The post is about visiting the beach and enjoying sunshine, which suggests a trip or travel as the main theme.\"}\n",
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action, nor does it indicate the user is seeking to acquire knowledge or skills related to carrying out violence. There is no discussion about logistics, timelines, specific targets, or coordination with others. The text does not contain any 'leakage' revealing the user's intentions or plans. The overall tone and emotional intensity of the post do not suggest excessive punctuation marks, strong expressions of anger or excitement, or a sense of urgency. Therefore, the post exhibits no signs of operational planning for extremist activities.\" }\n",
      "{ \"theme\": \"Travel\", \"reasoning\": \"The post talks about visiting the beach, which is a prominent subject and can be summarized as 'Travel'.\" }\n",
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action. There are no indicators that the user is seeking to acquire knowledge or skills related to carrying out violence. The post does not include discussion about logistics, timelines, specific targets, or coordination with others. There is no 'leakage' where the user might be unintentionally revealing their intentions or plans. The overall tone and emotional intensity of the post do not indicate an individual close to taking action.\" }\n",
      "{\"theme\": \"Travel\", \"reasoning\": \"The post talks about visiting the beach, which is a common association with travel and vacation.\"}\n",
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action, nor does it indicate the user is seeking knowledge or skills related to carrying out violence. There is no discussion about logistics, timelines, or coordination with others. The text does not reveal any 'leakage' of intentions or plans. The tone is neutral, without excessive punctuation or emotional intensity. Overall, the post does not exhibit strong, moderate, weak, or no signs of operational planning for extremist activities.\" }\n",
      "{ \"theme\": \"Travel\", \"reasoning\": \"The post is about visiting the beach, which is a common association with travel and vacation.\" }\n",
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action, nor does it indicate the user is seeking knowledge or skills related to carrying out violence. There is no discussion about logistics, timelines, specific targets, or coordination with others. The text does not contain any 'leakage' revealing the user's intentions or plans. The overall tone and emotional intensity of the post do not suggest excessive punctuation marks, strong expressions of anger or excitement, or a sense of urgency that could indicate an individual is close to taking action.\" }\n",
      "{ \"theme\": \"Travel\", \"reasoning\": \"The post is about visiting the beach, which is a common tourist destination, indicating travel as the main theme.\" }\n",
      "{\"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action. There are no indicators that the user is seeking to acquire knowledge or skills related to carrying out violence. The post does not include discussion about logistics, timelines, specific targets, or coordination with others. The text does not contain any 'leakage' where the user might be unintentionally revealing their intentions or plans. The overall tone and emotional intensity of the post do not suggest excessive punctuation marks, strong expressions of anger or excitement, or a sense of urgency that could indicate an individual is close to taking action. Therefore, the post exhibits no signs of operational planning for extremist activities.\"}\n",
      "{\"theme\": \"Travel\", \"reasoning\": \"The post is about visiting the beach and enjoying sunshine, which is a common association with traveling.\"}\n",
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action, nor does it indicate the user is seeking to acquire knowledge or skills related to carrying out violence. There is no discussion about logistics, timelines, specific targets, or coordination with others. The text does not contain any 'leakage' of intentions or plans. The overall tone and emotional intensity of the post are neutral, with no excessive punctuation marks, strong expressions of anger or excitement, or a sense of urgency that could indicate an individual is close to taking action.\" }\n",
      "{\"theme\": \"Travel\", \"reasoning\": \"The post mentions visiting the beach and enjoying sunshine, which indicates a trip or travel activity as the main theme.\"}\n",
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action. There are no indicators of the user seeking to acquire knowledge or skills related to carrying out violence. The post does not include discussion about logistics, timelines, specific targets, or coordination with others. There is no 'leakage' of the user's intentions or plans. The overall tone and emotional intensity of the post do not suggest excessive punctuation marks, strong expressions of anger or excitement, or a sense of urgency. Therefore, the post exhibits no signs of operational planning for extremist activities.\" }\n",
      "{ \"theme\": \"Travel\", \"reasoning\": \"The post talks about visiting the beach, which is a prominent subject indicating travel as the main theme.\" }\n",
      "{\"is_operational_planning\": \"no\", \"reasoning\": \"The post contains no keywords or phrases related to violent action, nor are there any indicators of seeking knowledge or skills for carrying out violence. There is no discussion about logistics, timelines, or coordination with others. The text does not contain any leakage of intentions or plans. The tone is neutral, and there are no excessive punctuation marks or strong expressions of anger or excitement. Therefore, the post exhibits no signs of operational planning for extremist activities.\"}\n",
      "{\"theme\": \"Travel\", \"reasoning\": \"The post is about visiting the beach, which is a common tourist destination associated with travel and leisure.\"}\n",
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action, nor does it indicate the user is seeking to acquire knowledge or skills related to carrying out violence. There is no discussion about logistics, timelines, specific targets, or coordination with others. The text does not contain any 'leakage' revealing the user's intentions or plans. The overall tone and emotional intensity of the post do not suggest excessive punctuation marks, strong expressions of anger or excitement, or a sense of urgency that could indicate an individual is close to taking action.\" }\n",
      "{\"theme\": \"Travel\", \"reasoning\": \"The post is about visiting the beach, which is a common association with travel and tourism.\"}\n",
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action. There are no indicators that the user is seeking to acquire knowledge or skills related to carrying out violence. The post does not include discussion about logistics, timelines, specific targets, or coordination with others. There is no 'leakage' in the text where the user might be unintentionally revealing their intentions or plans. The overall tone and emotional intensity of the post are neutral, without excessive punctuation marks, strong expressions of anger or excitement, or a sense of urgency.\" }\n",
      "{ \"theme\": \"Travel\", \"reasoning\": \"The post is about visiting the beach, which is a common tourist destination, indicating travel as the main theme.\" }\n",
      "{ \"is_operational_planning\": \"no\", \"reasoning\": \"The post does not contain any keywords or phrases related to violent action. There are no indicators of the user seeking knowledge or skills related to carrying out violence. The post does not include discussion about logistics, timelines, specific targets, or coordination with others. There is no 'leakage' of intentions or plans. The overall tone and emotional intensity of the post are neutral, with no excessive punctuation marks, strong expressions of anger or excitement, or a sense of urgency.\" }\n",
      "{\"theme\": \"Travel\", \"reasoning\": \"The post is about visiting the beach, which indicates travel as the main theme.\"}\n",
      "{  \"is_operational_planning\": \"no\",  \"reasoning\": \"The post does not contain any keywords or phrases related to violent action, indicators of seeking knowledge or skills related to carrying out violence, discussion about logistics, timelines, specific targets, or coordination with others. There is no 'leakage' revealing intentions or plans, and the overall tone and emotional intensity do not suggest excessive urgency or strong expressions of anger or excitement.\" }\n",
      "{\"theme\": \"Travel\", \"reasoning\": \"The post mentions visiting the beach and enjoying sunshine, which indicates a trip or travel-related activity as the main theme.\"}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The schema argument must be a Pydantic model class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m timeline \u001b[38;5;241m=\u001b[39m TimelineObject(feature_extractor)\n\u001b[0;32m     17\u001b[0m timeline\u001b[38;5;241m.\u001b[39mposts \u001b[38;5;241m=\u001b[39m posts\n\u001b[1;32m---> 18\u001b[0m \u001b[43mtimeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHOSEN_OVERALL_WINDOW_START\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHOSEN_OVERALL_WINDOW_END\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Get the window object\u001b[39;00m\n\u001b[0;32m     21\u001b[0m window \u001b[38;5;241m=\u001b[39m timeline\u001b[38;5;241m.\u001b[39mwindows[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\JS\\Documents\\tools\\Tribal\\Tribal\\objects\\timeline.py:53\u001b[0m, in \u001b[0;36mTimelineObject.make_new_window\u001b[1;34m(self, start_time, end_time, window_name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_new_window\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_time, end_time, window_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     52\u001b[0m     filtered_posts \u001b[38;5;241m=\u001b[39m [post \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_posts \u001b[38;5;28;01mif\u001b[39;00m start_time \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m post\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_time]\n\u001b[1;32m---> 53\u001b[0m     window \u001b[38;5;241m=\u001b[39m \u001b[43mWindowObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_extractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_posts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_windows\u001b[38;5;241m.\u001b[39mappend(window)\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m window\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\Tribal\\objects\\window.py:34\u001b[0m, in \u001b[0;36mWindowObject.__init__\u001b[1;34m(self, feature_extractor, posts, start_date, end_date, window_name)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_date \u001b[38;5;241m=\u001b[39m start_date\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_date \u001b[38;5;241m=\u001b[39m end_date\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialise_window_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\Tribal\\objects\\window.py:55\u001b[0m, in \u001b[0;36mWindowObject._initialise_window_data\u001b[1;34m(self, posts)\u001b[0m\n\u001b[0;32m     53\u001b[0m user\u001b[38;5;241m.\u001b[39musername \u001b[38;5;241m=\u001b[39m username\n\u001b[0;32m     54\u001b[0m user\u001b[38;5;241m.\u001b[39mcentrality \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_centrality_for_user(username)\n\u001b[1;32m---> 55\u001b[0m user\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_role_for_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m user\u001b[38;5;241m.\u001b[39mextremism \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extremism_for_user(username)\n\u001b[0;32m     58\u001b[0m list_of_user_objects\u001b[38;5;241m.\u001b[39mappend(user)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\Tribal\\objects\\window.py:138\u001b[0m, in \u001b[0;36mWindowObject._get_role_for_user\u001b[1;34m(self, user)\u001b[0m\n\u001b[0;32m    135\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m post\u001b[38;5;241m.\u001b[39musername \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m post\u001b[38;5;241m.\u001b[39mpost\n\u001b[0;32m    137\u001b[0m schema \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe role of People Leader, Leader Influencer, Engager Negator, Engager Supporter, Engager Neutral, Bystander, or NATTAC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrational\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe rational for why.\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m--> 138\u001b[0m structured_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_json_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_extractor\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mask_question(structured_prompt)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_extractor\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mreset_dialogue()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\Tribal\\utils\\easy_llm.py:360\u001b[0m, in \u001b[0;36mEasyLLM.generate_json_prompt\u001b[1;34m(self, schema, query)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# Ensure schema is a class (Type[BaseModel])\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(schema, BaseModel):\n\u001b[1;32m--> 360\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe schema argument must be a Pydantic model class.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# Initialize the JSON output parser with your schema\u001b[39;00m\n\u001b[0;32m    363\u001b[0m parser \u001b[38;5;241m=\u001b[39m JsonOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mschema)\n",
      "\u001b[1;31mTypeError\u001b[0m: The schema argument must be a Pydantic model class."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define the pickle file name\n",
    "pickle_file = 'window.pkl'\n",
    "\n",
    "# Try to load the pickled window if it exists\n",
    "if os.path.exists(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        window = pickle.load(f)\n",
    "    print(\"Loaded the pickled window.\")\n",
    "else:\n",
    "    print(\"Pickle file does not exist. Creating a new window.\")\n",
    "\n",
    "    # Assuming 'timeline' object and 'posts' are already defined\n",
    "    timeline = TimelineObject(feature_extractor)\n",
    "    timeline.posts = posts\n",
    "    timeline.make_new_window(CHOSEN_OVERALL_WINDOW_START, CHOSEN_OVERALL_WINDOW_END)\n",
    "\n",
    "    # Get the window object\n",
    "    window = timeline.windows[0]\n",
    "\n",
    "    # Save the window object to a pickle file\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(window, f)\n",
    "    print(\"Created and pickled a new window.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'window' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m node_labels \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Placeholder for node labels\u001b[39;00m\n\u001b[0;32m     21\u001b[0m node_features \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Placeholder for feature vectors\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m \u001b[43mwindow\u001b[49m\u001b[38;5;241m.\u001b[39musers\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m     24\u001b[0m     user_data \u001b[38;5;241m=\u001b[39m user\u001b[38;5;241m.\u001b[39mget_dict()\n\u001b[0;32m     25\u001b[0m     centrality \u001b[38;5;241m=\u001b[39m user_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcentrality\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'window' is not defined"
     ]
    }
   ],
   "source": [
    "# Block 4: Extract user features and populate the graph\n",
    "current_ops_index = 0\n",
    "current_theme_index = 0\n",
    "current_role_index = 0\n",
    "\n",
    "# Dictionaries to map operational states, themes, and roles to numerical values\n",
    "ops_to_num = {}\n",
    "num_to_ops = {}\n",
    "\n",
    "theme_to_num = {}\n",
    "num_to_theme = {}\n",
    "\n",
    "role_to_num = {}\n",
    "num_to_role = {}\n",
    "\n",
    "# Define the fixed set of POS tags and emotions based on your dataset\n",
    "pos_tags = ['NN', 'VB', 'JJ', 'RB']  # Noun, Verb, Adjective, Adverb (example)\n",
    "emotions = ['anger', 'fear', 'joy', 'sadness', 'surprise', 'disgust']  \n",
    "\n",
    "node_labels = []  # Placeholder for node labels\n",
    "node_features = []  # Placeholder for feature vectors\n",
    "\n",
    "for user in window.users.values():\n",
    "    user_data = user.get_dict()\n",
    "    centrality = user_data[\"centrality\"]\n",
    "    avrg_sentiment = user_data[\"avrg_sentiment\"]\n",
    "    avrg_toxicity = user_data[\"avrg_toxicity\"]\n",
    "    operational = user_data[\"avrg_is_operational\"]\n",
    "    extremism = user_data[\"extremism\"]\n",
    "    role = user_data[\"role\"]\n",
    "    avrg_capital_letter_word_frequency = user_data[\"avrg_capital_letter_word_frequency\"]\n",
    "    avrg_emotion_scores = user_data[\"avrg_emotion_scores\"]\n",
    "    average_hate_speech_lexicon_counts = user_data[\"average_hate_speech_lexicon_counts\"]\n",
    "    avrg_text_vector = user_data[\"avrg_text_vector\"]  # This should be a list or numpy array\n",
    "    avrg_pos_counts = user_data[\"avrg_pos_counts\"]  # Dictionary of POS counts\n",
    "\n",
    "    # Handling operational mapping\n",
    "    if operational not in ops_to_num:\n",
    "        ops_to_num[operational] = current_ops_index\n",
    "        num_to_ops[current_ops_index] = operational\n",
    "        current_ops_index += 1\n",
    "    operational_num = ops_to_num[operational]\n",
    "\n",
    "    # Handling theme mapping\n",
    "    theme = user_data[\"avrg_theme\"]\n",
    "    if theme not in theme_to_num:\n",
    "        theme_to_num[theme] = current_theme_index\n",
    "        num_to_theme[current_theme_index] = theme\n",
    "        current_theme_index += 1\n",
    "    avrg_theme_num = theme_to_num[theme]\n",
    "\n",
    "    # Handling role mapping\n",
    "    if role not in role_to_num:\n",
    "        role_to_num[role] = current_role_index\n",
    "        num_to_role[current_role_index] = role\n",
    "        current_role_index += 1\n",
    "    role_num = role_to_num[role]\n",
    "\n",
    "    # Processing POS counts into a fixed-size vector\n",
    "    pos_counts_vector = [avrg_pos_counts.get(tag, 0) for tag in pos_tags]\n",
    "\n",
    "    # Processing emotion scores into a fixed-size vector\n",
    "    emotion_scores_vector = [avrg_emotion_scores.get(emotion, 0.0) for emotion in emotions]\n",
    "\n",
    "    # Summing the average hate speech lexicon counts\n",
    "    average_hate_speech_count = sum(average_hate_speech_lexicon_counts.values())\n",
    "\n",
    "    # Ensure avrg_text_vector is a list (convert if necessary)\n",
    "    if isinstance(avrg_text_vector, np.ndarray):\n",
    "        avrg_text_vector = avrg_text_vector.tolist()\n",
    "\n",
    "    # Create the feature vector by concatenating all features\n",
    "    feature_vector = [\n",
    "        centrality,\n",
    "        avrg_sentiment,\n",
    "        avrg_toxicity,\n",
    "        operational_num,\n",
    "        avrg_theme_num,\n",
    "        extremism,\n",
    "        role_num,\n",
    "        avrg_capital_letter_word_frequency,\n",
    "        average_hate_speech_count,\n",
    "    ] + pos_counts_vector + emotion_scores_vector + avrg_text_vector\n",
    "\n",
    "    # Append the feature vector and label\n",
    "    node_features.append(feature_vector)\n",
    "    node_labels.append(extremism)  # Assuming 'extremism' is the label (adjust if necessary)\n",
    "\n",
    "    # Add the node to the graph\n",
    "    graph.add_node(user_data[\"username\"], profile=torch.tensor(feature_vector, dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5: Extract user features and populate the graph\n",
    "current_ops_index = 0\n",
    "current_theme_index = 0\n",
    "current_role_index = 0\n",
    "\n",
    "# Dictionaries to map operational states, themes, and roles to numerical values\n",
    "ops_to_num = {}\n",
    "num_to_ops = {}\n",
    "\n",
    "theme_to_num = {}\n",
    "num_to_theme = {}\n",
    "\n",
    "role_to_num = {}\n",
    "num_to_role = {}\n",
    "\n",
    "for username, user in window.users.items():\n",
    "    user_data = user.get_dict()\n",
    "    centrality = user_data.get(\"centrality\", 0)\n",
    "    avrg_sentiment = user_data.get(\"avrg_sentiment\", 0)\n",
    "    avrg_toxicity = user_data.get(\"avrg_toxicity\", 0)\n",
    "    operational = user_data.get(\"avrg_is_operational\", 'unknown')\n",
    "    extremism = user_data.get(\"extremism\", 0)\n",
    "    role = user_data.get(\"role\", 'unknown')\n",
    "\n",
    "    # Handling operational mapping\n",
    "    if operational not in ops_to_num:\n",
    "        ops_to_num[operational] = current_ops_index\n",
    "        num_to_ops[current_ops_index] = operational\n",
    "        current_ops_index += 1\n",
    "    operational_num = ops_to_num[operational]\n",
    "\n",
    "    # Handling theme mapping\n",
    "    theme = user_data.get(\"avrg_theme\", 'unknown')\n",
    "    if theme not in theme_to_num:\n",
    "        theme_to_num[theme] = current_theme_index\n",
    "        num_to_theme[current_theme_index] = theme\n",
    "        current_theme_index += 1\n",
    "    avrg_theme_num = theme_to_num[theme]\n",
    "\n",
    "    # Handling role mapping\n",
    "    if role not in role_to_num:\n",
    "        role_to_num[role] = current_role_index\n",
    "        num_to_role[current_role_index] = role\n",
    "        current_role_index += 1\n",
    "    role_num = role_to_num[role]\n",
    "\n",
    "    # Create feature vector: centrality, sentiment, toxicity, operational, theme, extremism, role\n",
    "    feature_vector = [\n",
    "        centrality, \n",
    "        avrg_sentiment, \n",
    "        avrg_toxicity, \n",
    "        operational_num, \n",
    "        avrg_theme_num, \n",
    "        extremism, \n",
    "        role_num\n",
    "    ]\n",
    "\n",
    "    # Append the feature vector and label\n",
    "    node_features.append(torch.tensor(feature_vector, dtype=torch.float))\n",
    "    node_labels.append(extremism)\n",
    "\n",
    "    # Add the node to the graph\n",
    "    graph.add_node(username, profile=torch.tensor(feature_vector, dtype=torch.float))\n",
    "\n",
    "    # Add edges based on connections (assuming user_data contains 'connections')\n",
    "    connections = user_data.get('connections', [])\n",
    "    for connected_user in connections:\n",
    "        graph.add_edge(username, connected_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6: Convert NetworkX graph to PyTorch Geometric format\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "data = from_networkx(graph)\n",
    "\n",
    "# Update node features and labels\n",
    "data.x = torch.stack([graph.nodes[node]['profile'] for node in graph.nodes])\n",
    "data.y = torch.tensor(node_labels, dtype=torch.long)  # Labels for each node (extremist or non-extremist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 7: Split data into train, validation, and test sets\n",
    "train_mask_indices, val_test_mask_indices = train_test_split(\n",
    "    range(data.num_nodes), test_size=0.4, random_state=42\n",
    ")\n",
    "val_mask_indices, test_mask_indices = train_test_split(\n",
    "    val_test_mask_indices, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Create mask tensors for train, validation, and test sets\n",
    "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "train_mask[train_mask_indices] = True\n",
    "\n",
    "val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "val_mask[val_mask_indices] = True\n",
    "\n",
    "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "test_mask[test_mask_indices] = True\n",
    "\n",
    "# Assign masks to data\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 8: Define GCN model for node classification\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 9: Initialize model, optimizer, and loss function\n",
    "input_dim = data.x.shape[1]  # Updated input dimension based on new feature vector size\n",
    "hidden_dim = 64  # You can adjust this value\n",
    "output_dim = 2   # Assuming binary classification (extremist or non-extremist)\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(in_channels=input_dim, hidden_channels=hidden_dim, out_channels=output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 10: Function to evaluate model accuracy\n",
    "def evaluate(mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)  # Forward pass\n",
    "        pred = out.argmax(dim=1)  # Get predicted classes\n",
    "        correct = pred[mask].eq(data.y[mask]).sum().item()  # Count correct predictions\n",
    "        accuracy = correct / mask.sum().item()  # Compute accuracy\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 11: Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        train_acc = evaluate(data.train_mask)\n",
    "        val_acc = evaluate(data.val_mask)\n",
    "        print(\n",
    "            f'Epoch {epoch}, Loss: {loss.item():.4f}, '\n",
    "            f'Train Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 12: Evaluate model on the test set\n",
    "test_acc = evaluate(data.test_mask)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 13: Function to predict the effect of adding a user\n",
    "def predict_add_user_gnn(new_user_id, new_user_features, connections, graph, model):\n",
    "    print(f\"Predicting changes by adding user {new_user_id}...\")\n",
    "\n",
    "    # Add the new user node and connections\n",
    "    graph.add_node(\n",
    "        new_user_id, \n",
    "        profile=torch.tensor(new_user_features, dtype=torch.float)\n",
    "    )\n",
    "    for connection in connections:\n",
    "        graph.add_edge(new_user_id, connection)\n",
    "\n",
    "    # Convert updated graph to PyTorch Geometric format\n",
    "    data = from_networkx(graph)\n",
    "    data.x = torch.stack([graph.nodes[node]['profile'] for node in graph.nodes])\n",
    "    data.edge_index = torch.tensor(\n",
    "        list(graph.edges), dtype=torch.long\n",
    "    ).t().contiguous()\n",
    "\n",
    "    # Predict using the GCN\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "\n",
    "    predicted_features = out[-1]  # Assuming the new user is the last node\n",
    "    print(f\"Predicted features for new user {new_user_id}: {predicted_features}\")\n",
    "    return predicted_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 14: Function to predict the effect of removing a user\n",
    "def predict_remove_user_gnn(user_id, graph, model):\n",
    "    print(f\"Predicting changes by removing user {user_id}...\")\n",
    "\n",
    "    if graph.has_node(user_id):\n",
    "        graph.remove_node(user_id)\n",
    "    else:\n",
    "        print(f\"User {user_id} does not exist in the graph.\")\n",
    "        return None\n",
    "\n",
    "    data = from_networkx(graph)\n",
    "    data.x = torch.stack([graph.nodes[node]['profile'] for node in graph.nodes])\n",
    "    data.edge_index = torch.tensor(\n",
    "        list(graph.edges), dtype=torch.long\n",
    "    ).t().contiguous()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "\n",
    "    print(\n",
    "        f\"Predicted features for the remaining nodes after removing user {user_id}: {out}\"\n",
    "    )\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 15: Example usage of prediction functions\n",
    "new_user_id = 'new_user'\n",
    "new_user_features = [\n",
    "    0.6, 0.5, 0.4, \n",
    "    ops_to_num.get('unknown', 0), \n",
    "    theme_to_num.get('unknown', 0), \n",
    "    0,  # extremism\n",
    "    role_to_num.get('unknown', 0)\n",
    "]  # Example features\n",
    "connections = ['some_user', 'another_user']  # Example connections to other users\n",
    "\n",
    "# Predict effect of adding a user\n",
    "predicted_features = predict_add_user_gnn(\n",
    "    new_user_id, new_user_features, connections, graph, model\n",
    ")\n",
    "\n",
    "# Predict effect of removing a user\n",
    "removed_user_predictions = predict_remove_user_gnn('some_user', graph, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 16: Function to predict missing features after removing and re-adding a user\n",
    "def predict_removed_user_features(user_id, graph, model):\n",
    "    if not graph.has_node(user_id):\n",
    "        print(f\"User {user_id} does not exist in the graph.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Removing user {user_id} from the graph...\")\n",
    "    user_profile = graph.nodes[user_id]['profile']\n",
    "    graph.remove_node(user_id)\n",
    "\n",
    "    incomplete_profile = user_profile.clone()\n",
    "    incomplete_profile[1:3] = float('nan')\n",
    "    print(\n",
    "        f\"Stripped features (sentiment and toxicity) for user {user_id}: {incomplete_profile}\"\n",
    "    )\n",
    "\n",
    "    print(f\"Re-adding user {user_id} with missing features...\")\n",
    "    graph.add_node(user_id, profile=incomplete_profile)\n",
    "\n",
    "    original_connections = users[user_id].get('connections', [])\n",
    "    for connection in original_connections:\n",
    "        graph.add_edge(user_id, connection)\n",
    "\n",
    "    data = from_networkx(graph)\n",
    "    data.x = torch.stack([graph.nodes[node]['profile'] for node in graph.nodes])\n",
    "    data.edge_index = torch.tensor(\n",
    "        list(graph.edges), dtype=torch.long\n",
    "    ).t().contiguous()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted_features = model(data)\n",
    "\n",
    "    original_features = user_profile\n",
    "    node_index = list(graph.nodes).index(user_id)\n",
    "    predicted_features_for_user = predicted_features[node_index]\n",
    "    print(f\"Original features: {original_features}\")\n",
    "    print(f\"Predicted features: {predicted_features_for_user}\")\n",
    "\n",
    "    return original_features, predicted_features_for_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 17: Example usage of removing a user and predicting missing features\n",
    "user_to_remove = 'some_user'  # Specify the user ID to remove and test\n",
    "result = predict_removed_user_features(user_to_remove, graph, model)\n",
    "\n",
    "if result:\n",
    "    original, predicted = result\n",
    "    # Calculate the accuracy of the prediction for the missing features\n",
    "    missing_indices = [1, 2]  # Indices of the stripped features (sentiment and toxicity)\n",
    "    error = torch.abs(original[missing_indices] - predicted[missing_indices])\n",
    "    print(f\"Prediction error for missing features: {error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 18: Compute and plot correlation coefficients between features and \"extremism\" labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_correlation(data):\n",
    "    # Extract features (node features) and labels (extremism labels)\n",
    "    features = data.x  # This is the matrix of node features\n",
    "    labels = data.y  # This is the \"extremism\" label (0 or 1)\n",
    "\n",
    "    # Convert features and labels to numpy arrays for correlation calculation\n",
    "    features_np = features.numpy()\n",
    "    labels_np = labels.numpy()\n",
    "\n",
    "    # Calculate the correlation coefficient for each feature with respect to the labels\n",
    "    correlations = []\n",
    "    for i in range(features_np.shape[1]):\n",
    "        feature_column = features_np[:, i]\n",
    "        correlation = np.corrcoef(feature_column, labels_np)[0, 1]\n",
    "        correlations.append(correlation)\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# Calculate the correlation coefficients\n",
    "correlations = calculate_correlation(data)\n",
    "\n",
    "# Plotting the correlation coefficients as a bar graph\n",
    "feature_names = [\n",
    "    'Centrality', 'Sentiment', 'Toxicity', 'Operational Status', \n",
    "    'Theme', 'Extremism', 'Role'\n",
    "]  # Adjust feature names accordingly\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(correlations)), correlations, tick_label=feature_names)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation with Extremism')\n",
    "plt.title('Correlation between Features and Extremism')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
